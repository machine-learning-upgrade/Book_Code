{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ewI3se7iuXt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5235a2c-9aa2-4c0d-f1d7-478c0cf17e16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymilvus==2.3.4\n",
            "  Downloading pymilvus-2.3.4-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain==0.0.352\n",
            "  Downloading langchain-0.0.352-py3-none-any.whl (794 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.4/794.4 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==1.6.1\n",
            "  Downloading openai-1.6.1-py3-none-any.whl (225 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytube==15.0.0\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting youtube-transcript-api==0.6.1\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Collecting pyarrow==14.0.2\n",
            "  Downloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing_extensions==4.9.0\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting comet-ml==3.35.5\n",
            "  Downloading comet_ml-3.35.5-py3-none-any.whl (586 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.8/586.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<=1.58.0,>=1.49.1 (from pymilvus==2.3.4)\n",
            "  Downloading grpcio-1.58.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus==2.3.4) (3.20.3)\n",
            "Collecting environs<=9.5.0 (from pymilvus==2.3.4)\n",
            "  Downloading environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting ujson>=2.0.0 (from pymilvus==2.3.4)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus==2.3.4) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pymilvus==2.3.4) (2.31.0)\n",
            "Collecting minio>=7.0.0 (from pymilvus==2.3.4)\n",
            "  Downloading minio-7.2.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.352) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.352) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.352) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.352) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.0.352)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.0.352)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.2 (from langchain==0.0.352)\n",
            "  Downloading langchain_community-0.0.6-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1 (from langchain==0.0.352)\n",
            "  Downloading langchain_core-0.1.3-py3-none-any.whl (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.4/192.4 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1.0,>=0.0.70 (from langchain==0.0.352)\n",
            "  Downloading langsmith-0.0.74-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.352) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.352) (1.10.13)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.352) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.6.1) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.6.1)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.6.1) (4.66.1)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.35.5) (4.19.2)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.35.5) (5.9.5)\n",
            "Collecting python-box<7.0.0 (from comet-ml==3.35.5)\n",
            "  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt>=0.8.0 (from comet-ml==3.35.5)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version>=2.8.0 (from comet-ml==3.35.5)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sentry-sdk>=1.1.0 (from comet-ml==3.35.5)\n",
            "  Downloading sentry_sdk-1.39.1-py2.py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.1/254.1 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson (from comet-ml==3.35.5)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.35.5) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.35.5) (2.0.7)\n",
            "Collecting websocket-client<1.4.0,>=0.55.0 (from comet-ml==3.35.5)\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.35.5) (1.14.1)\n",
            "Collecting wurlitzer>=1.0.2 (from comet-ml==3.35.5)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Collecting everett[ini]<3.2.0,>=1.0.1 (from comet-ml==3.35.5)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet-ml==3.35.5)\n",
            "  Downloading dulwich-0.21.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (514 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m514.7/514.7 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet-ml==3.35.5) (13.7.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.352) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.352) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.352) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.352) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.352) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.6.1) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.6.1) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.352)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.352)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting python-dotenv (from environs<=9.5.0->pymilvus==2.3.4)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet-ml==3.35.5)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.6.1) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.6.1)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.6.1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.0.352)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml==3.35.5) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml==3.35.5) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet-ml==3.35.5) (0.15.2)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1->langchain==0.0.352) (23.2)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus==2.3.4) (23.1.0)\n",
            "Collecting pycryptodome (from minio>=7.0.0->pymilvus==2.3.4)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus==2.3.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus==2.3.4) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pymilvus==2.3.4) (3.3.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml==3.35.5) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet-ml==3.35.5) (2.16.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.352) (3.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet-ml==3.35.5) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.352)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio>=7.0.0->pymilvus==2.3.4) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus==2.3.4) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus==2.3.4) (2.21)\n",
            "Installing collected packages: everett, wurlitzer, websocket-client, ujson, typing_extensions, simplejson, sentry-sdk, semantic-version, pytube, python-dotenv, python-box, pycryptodome, pyarrow, mypy-extensions, marshmallow, jsonpointer, h11, grpcio, dulwich, configobj, youtube-transcript-api, typing-inspect, requests-toolbelt, jsonpatch, httpcore, environs, langsmith, httpx, dataclasses-json, openai, minio, langchain-core, comet-ml, pymilvus, langchain-community, langchain\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.7.0\n",
            "    Uninstalling websocket-client-1.7.0:\n",
            "      Successfully uninstalled websocket-client-1.7.0\n",
            "  Attempting uninstall: typing_extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: python-box\n",
            "    Found existing installation: python-box 7.1.1\n",
            "    Uninstalling python-box-7.1.1:\n",
            "      Successfully uninstalled python-box-7.1.1\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.60.0\n",
            "    Uninstalling grpcio-1.60.0:\n",
            "      Successfully uninstalled grpcio-1.60.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "ibis-framework 6.2.0 requires pyarrow<13,>=2, but you have pyarrow 14.0.2 which is incompatible.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed comet-ml-3.35.5 configobj-5.0.8 dataclasses-json-0.6.3 dulwich-0.21.7 environs-9.5.0 everett-3.1.0 grpcio-1.58.0 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.352 langchain-community-0.0.6 langchain-core-0.1.3 langsmith-0.0.74 marshmallow-3.20.1 minio-7.2.0 mypy-extensions-1.0.0 openai-1.6.1 pyarrow-14.0.2 pycryptodome-3.19.0 pymilvus-2.3.4 python-box-6.1.0 python-dotenv-1.0.0 pytube-15.0.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-1.39.1 simplejson-3.19.2 typing-inspect-0.9.0 typing_extensions-4.9.0 ujson-5.9.0 websocket-client-1.3.3 wurlitzer-3.0.3 youtube-transcript-api-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install \\\n",
        "  pymilvus==2.3.4 \\\n",
        "  langchain==0.0.352 \\\n",
        "  openai==1.6.1 \\\n",
        "  pytube==15.0.0 \\\n",
        "  youtube-transcript-api==0.6.1 \\\n",
        "  pyarrow==14.0.2 \\\n",
        "  typing_extensions==4.9.0 \\\n",
        "  comet-ml==3.35.5\n",
        "\n",
        "# Restart the runtime after pip installing (CTRL + M)  Otherwise, the runtime\n",
        "# remembers the old version of pyArrow and causes issues for pyMilvus\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import (MilvusClient\n",
        "                      , connections\n",
        "                      , Collection\n",
        "                      , CollectionSchema\n",
        "                      , FieldSchema\n",
        "                      , DataType\n",
        "                      , utility)\n",
        "import json\n",
        "\n",
        "\n",
        "COLLECTION_NAME = 'youtube'\n",
        "EMBEDDING_DIMENSION = 1536  # Embedding vector size in this example\n",
        "ZILLIZ_CLUSTER_URI = 'https://in03-edd1f99a508a8c4.api.gcp-us-west1.zillizcloud.com'  # Endpoint URI obtained from Zilliz Cloud\n",
        "ZILLIZ_API_KEY = '46dcc1502bfcc6ea9f5869ef9481a0dd200bf426f92a7e26c77a96602c79bc1fe27cf5ff6cdae7acc29feba362ebc899fcb96cd9'\n",
        "\n",
        "YT_VIDEO_URLS = [\n",
        "    \"https://www.youtube.com/watch?v=Q4OBx3S0Ysw&t=118s\",\n",
        "    \"https://youtu.be/4OZip0cgOho?si=KHUsA4J8L3rbZAAZ\"]\n",
        "\n",
        "# Connect to the zilliz cluster\n",
        "connections.connect(uri=ZILLIZ_CLUSTER_URI, token=ZILLIZ_API_KEY, secure=True)\n",
        "\n",
        "# Remove any previous collections with the same name\n",
        "if utility.has_collection(COLLECTION_NAME):\n",
        "    utility.drop_collection(COLLECTION_NAME)\n",
        "\n",
        "# Create collection which includes the id, title, and embedding.\n",
        "fields = [\n",
        "  FieldSchema(name='id', dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=36),\n",
        "  FieldSchema(name='video_id', dtype=DataType.INT64,),\n",
        "  FieldSchema(name='title', dtype=DataType.VARCHAR, description='Title texts', max_length=500),\n",
        "  FieldSchema(name='author', dtype=DataType.VARCHAR, description='Author', max_length=200),\n",
        "  FieldSchema(name='part_id', dtype=DataType.INT64),\n",
        "  FieldSchema(name='max_part_id', dtype=DataType.INT64),\n",
        "  FieldSchema(name='text', dtype=DataType.VARCHAR, description='Text of chunk', max_length=2000),\n",
        "  FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, description='Embedding vectors', dim=EMBEDDING_DIMENSION)\n",
        "]\n",
        "\n",
        "schema = CollectionSchema(fields=fields)\n",
        "\n",
        "collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
        "\n",
        "# Create an index for the collection.\n",
        "index_params = {\n",
        "    'index_type': 'AUTOINDEX',\n",
        "    'metric_type': 'IP',\n",
        "    'params': {}\n",
        "}\n",
        "\n",
        "\n",
        "collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "\n"
      ],
      "metadata": {
        "id": "SxtZXNoewwpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c52e8b1-2ff1-4a1c-d381-0391eb451d4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Status(code=0, message=)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from pymilvus import MilvusClient, connections\n",
        "from uuid import uuid4\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "import youtube_transcript_api\n",
        "import pytube\n",
        "\n",
        "connections.connect(uri=ZILLIZ_CLUSTER_URI, token=ZILLIZ_API_KEY, secure=True)\n",
        "\n",
        "client = MilvusClient(\n",
        "    uri=ZILLIZ_CLUSTER_URI,\n",
        "    token=ZILLIZ_API_KEY)\n",
        "\n",
        "\n",
        "\n",
        "openai_client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key=\"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\",\n",
        ")\n",
        "\n",
        "# Extract embedding from text using OpenAI  string -> vector\n",
        "# This function is directly from https://docs.zilliz.com/docs/similarity-search-with-zilliz-cloud-and-openai, but with \"text-embedding-ada-002\" added.\n",
        "def create_embedding_from_string(text):\n",
        "    return openai_client.embeddings.create(\n",
        "        input=text,\n",
        "        model='text-embedding-ada-002').data[0].embedding\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "  chunk_size = 1000,\n",
        "  chunk_overlap  = 50,\n",
        "  length_function = len,\n",
        "  add_start_index = True,\n",
        ")\n",
        "\n",
        "for video_id, url in enumerate(YT_VIDEO_URLS):\n",
        "\n",
        "  yt_data = YoutubeLoader.from_youtube_url(url, add_video_info=True).load()[0]\n",
        "  video_parts = text_splitter.create_documents([yt_data.page_content])\n",
        "\n",
        "  for part_id, part in enumerate(video_parts):\n",
        "      id = str(uuid4())\n",
        "      print(f'uplading document {id}... {yt_data.metadata[\"title\"]}')\n",
        "      client.insert(\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        data={\n",
        "            'id': id,\n",
        "            'video_id': video_id,\n",
        "            'title': yt_data.metadata['title'],\n",
        "            'author': yt_data.metadata['author'],\n",
        "            'part_id': part_id,\n",
        "            'max_part_id': len(video_parts),\n",
        "            'text': part.page_content,\n",
        "            'embedding': create_embedding_from_string(part.page_content)\n",
        "        })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVOv0eDFXjLM",
        "outputId": "4953d5f7-d9b6-48a6-a381-9feddb70c515"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:pymilvus.milvus_client.milvus_client:Created new connection using: 952cf4c312fc48efac2d530d3866669e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "uplading document 33747bbd-7c01-40e6-b148-8e84bada6873... Vector Similarity Search using Images with Zilliz\n",
            "uplading document de1e9677-a8e5-43cd-8693-406cd4cb74ed... Vector Similarity Search using Images with Zilliz\n",
            "uplading document 8ffc9916-fa4e-4565-aace-38f4dc43bf8f... Vector Similarity Search using Images with Zilliz\n",
            "uplading document 22647197-60dc-49cd-b617-7f9a58e8db5b... Vector Similarity Search using Images with Zilliz\n",
            "uplading document 4f53953a-f33a-406a-b70e-433989f7a87c... Vector Similarity Search using Images with Zilliz\n",
            "uplading document 37010a8c-2a24-41d3-b71a-d9574b0b3459... Vector Similarity Search using Images with Zilliz\n",
            "uplading document 03708004-1b7c-417b-9767-20d98ae55c3d... Vector Similarity Search using Images with Zilliz\n",
            "uplading document 5a21f463-f188-47b9-b082-d2620eb9543a... Vector Similarity Search using Images with Zilliz\n",
            "uplading document 8b73ad94-3081-440f-956b-47bf19d4290b... Vector Similarity Search using Images with Zilliz\n",
            "uplading document 4f493951-9058-480e-8e11-6a43a12f0760... How I Would Learn Data Science (If I Had to Start Over)\n",
            "uplading document d9032acf-a05d-4121-ac95-07e89c6f2c42... How I Would Learn Data Science (If I Had to Start Over)\n",
            "uplading document 57b14c48-30e1-4a49-99f7-9d17909e352a... How I Would Learn Data Science (If I Had to Start Over)\n",
            "uplading document be0cf9d1-5434-4a50-b0b2-28e5a3b60996... How I Would Learn Data Science (If I Had to Start Over)\n",
            "uplading document a4465a7f-d9f0-44bc-8a99-fa971ac81cbc... How I Would Learn Data Science (If I Had to Start Over)\n",
            "uplading document 1cd94734-10ec-420a-9497-6cb30ee76fcf... How I Would Learn Data Science (If I Had to Start Over)\n",
            "uplading document 09b67681-f559-4d66-8de9-ccac628f4bf9... How I Would Learn Data Science (If I Had to Start Over)\n",
            "uplading document f50d8fe9-c7da-40ce-acda-59ea4cc7c91e... How I Would Learn Data Science (If I Had to Start Over)\n",
            "uplading document f374c6bc-96bb-455b-91cc-795a69784c86... How I Would Learn Data Science (If I Had to Start Over)\n",
            "uplading document 8aa3b22b-8569-418d-b88b-0b256bd35ae1... How I Would Learn Data Science (If I Had to Start Over)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The collection must be \"LOADED\" in zilliz for this to work.\n",
        "results = collection.query(\n",
        "    expr='title != \"none\"',\n",
        "    output_fields=['title', 'author', 'part_id', 'max_part_id', 'text'])\n",
        "\n",
        "with open('data.json', 'w') as file:\n",
        "  file.write(json.dumps(results, indent=2))"
      ],
      "metadata": {
        "id": "aeBj9xabXfyN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## import comet_ml at the top of your file\n",
        "from comet_ml import Experiment, Artifact\n",
        "\n",
        "## Create an experiment with your api key\n",
        "experiment = Experiment(\n",
        "    api_key=\'YOUR API KEY\",\n',
        "    project_name=\'youtube-transcriptions\',\n",
        "    workspace=\'YOU USERNAME\',\n",
        ")\n",
        "\n",
        "artifact = Artifact(name=\"milvus-query-results\", artifact_type=\"dataset\")\n",
        "artifact.add(\"data.json\")\n",
        "\n",
        "experiment.log_artifact(artifact)\n",
        "experiment.end()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq34gBPbucza",
        "outputId": "8f321dc8-7e62-49b8-e91f-08e895e5bbc7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/machine-learning-upgrade/youtube-transcriptions/d7f084b96cf74ec182d769fd844e49b9\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'milvus-query-results' version 7.0.0 created (previous was: 6.0.0)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Scheduling the upload of 1 assets for a size of 21.01 KB, this can take some time\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'machine-learning-upgrade/milvus-query-results:7.0.0' has started uploading asynchronously\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/machine-learning-upgrade/youtube-transcriptions/d7f084b96cf74ec182d769fd844e49b9\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact assets     : 1 (21.01 KB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifacts           : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m All assets have been sent, waiting for delivery confirmation\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'machine-learning-upgrade/milvus-query-results:7.0.0' has been fully uploaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "\n",
        "loader = YoutubeLoader.from_youtube_url(\n",
        "    \"https://www.youtube.com/watch?v=Q4OBx3S0Ysw&t=118s\", add_video_info=True\n",
        ")\n",
        "\n",
        "data = loader.load()\n",
        "data[0].page_content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "6QK8fahg58gp",
        "outputId": "c9ca0f44-37b0-483b-8c51-2086f591ed6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"foreign [Applause] to perform Vector similarity search on images zillas is a vector database it is designed to handle massive data sets containing vectors vectors are just numerical representations of data so this is your text documents audio and that also includes images traditional methods of searching through these large data sets has been consuming and computationally expensive so zilis uses Advanced algorithms and data structures tailored specifically for Vector similarity search instead of comparing each point individually zilla's organizes these vectors in a way that optimizes similarity queries this allows you to quickly find items that are similar to a given query vector so is this focused on cutting-edge Technologies for data indexing storage and retrieval with an emphasis on GPU accelerated computing for a high level overview of this project we are going to get the connection from The Notebook to Melvis and set up a cluster we're going to import images from Google Drive I'll make sure to leave a link in the description we're going to set up zilla's Cloud we're going to insert our data and then we will do our similarity search using a resnet 50 model and then we're going to go back again and do it with resnet 152 to just compare the output and see how it's different to get started the first thing that you'll want to do is set yourself up azilla's account when you do that you will have a hundred dollars worth of free credits so that you'll be able to follow along with this demo for free I'm going to create a cluster and then we'll go over downloading the images creating the embeddings modeling those but then we'll be able to write those embeddings over to the milvis database I will be using the starter serverless plan and I'm just going to give this the name image search so that's the name of my collection the metric type there are two options and I'm going to be choosing this L2 which is just your standard euclidean distance all right so now I am going to put the public endpoint in my code I already have the API key over there copy this and you'll see that image search has been set up but that it doesn't actually have any data for us I'm going to add my URI [Music] like I said my API key is already here all right so now we're going to dive into this demo here is a Google Drive link that you can use to access the images that I'm using they are images of my family but if you want to go along with your own images that'll work too so we're starting like we normally do by pip installing our packages we'll restart our run time and then now I am just going to be setting up my directory to match the docs and so we are in the content folder and then I'll add one for python as well oh okay so now this should work all right so we are going to pip install a couple more libraries Pine milfus is going to be used to connect to zilla's Cloud we're going to use torch to run the embedding model we will use torch vision for the actual model and pre-processing and then G down is for working with Google Drive and the tqdm package is so that we get those cute little loading bars while our model is training then we will import these libraries here are the docs for starting here these docs are what I followed to put this together and so here you're going to need to add the Google Drive Link so you could use the link above open that up actually let me make sure that that works then we are going to set the output path and file name for the downloaded file and then download the file from the given Google Drive Link using gdam all right perfect so that link I gave you works next we're just going to be setting our parameters so we had given the collection name image search you had already seen me put my URI and I had already put my API key here and then now we need to set up our cloud so we will be first connecting to the zillas cloud cluster using the URI that we had there it's just if the collection already exists drop it okay and now we're going to be setting up our schema so it's going to have the ID the file path and the image embedding and we will now create an index on that collection here is that L2 euclidean distance metric that we already talked about and this is just to get the file path of the different images we have 1619 images okay so here we are going to create our base model using resnet 50. and this is actually not creating the model it is defining the model if you haven't used torch before I learned this the first time that I use torch is that they actually build their neural net models sequentially by adding the different layers so that's where we get this sequential function here we're creating a preprocessor for making sure the images are the same size so we're going to resize crop normalize or at least we're setting up a preprocessor so we didn't actually do those steps here but we created a function that will allow us to do that now we're going to insert the data so this one takes a minute to run but we're going to embed the function that embeds the batch and inserts it then we're going to read the images into batches for embedding and insertion and here we're actually going to insert the data all right I hope you're ready because we are about to perform our search now for this I have already placed four images that all looked different that we can do our search on the code here is going to go through and embed the images so this is the process of converting these photos into vectors using our resnet 50 model and we are going to iterate through and use that preprocessor that we set up that'll crop and normalize the images um then we're going to do the search through these embeddings for similar images and then at the end um it'll be using matplotlib to set up a visual display for us that will list the search time and the distance of the chosen searched photo to the image that I provided okay so let's get started all right perfect so we have our output and I am just going to store this so that we are able to do a comparison in a little bit once we have the output from our next model okay and now I'm just going to go through and actually update this to be using resnet 152 and rerun [Music] awesome now we get to go take a look at these results I actually went back and ran this a couple more times myself and found that in general the resnet 152 model had shorter search times or shorter distances but that was not always the case at all and even in our results we're going to see a lot of instances where the resnet 50 has shorter distances here though we will see that the resnet 152 model the search time was about three times faster than resnet 152. taking a look at the first photo we see that all the distances for the resnet 152 model are shorter compared to the resnet 50 model and really the only photo that looks different here is the last result in the second row of results the distances are actually larger with the resnet 152 model and you can really see this because the second result returned from the 152 results my daughter has her arms in and we'd assume that the ones that have the arms out are going to be more similar to the given photo in the third row of results it's my daughter and husband with their arms up wearing coats and the distances again they're higher with the resnet 152 model even though these are super close results and you get to benefit from the faster search time in the fourth row of results all the images look really similar with the exception of where is my son placed because you can't really see him in the given photo and then in the search results he's sort of in different places the distance for the first result is very close but then the distance for the resnet 152 model is much larger for the other two photos but again the search was quicker I hope you enjoyed this demo where we did Vector similarity search using images be sure to like And subscribe and I look forward to seeing you in my next demo\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}
