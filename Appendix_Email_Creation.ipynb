{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/machine-learning-upgrade/book_code/blob/main/Appendix_Email_Creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "langchain - used here for our text splitter\n",
        "\n",
        "openai - To access OpenAI API and the LLM models there\n",
        "\n",
        "\n",
        "pymilvus - Milvus is an open source vector DB, but we'll be using Zilliz (managed Milvus)\n",
        "\n",
        "\n",
        "gradio - This is the dashboarding framework we're using\n",
        "\n",
        "\n",
        "pyarrow - Here I'm just looking to force the version so that it doesn't conflict with pymilvus\n"
      ],
      "metadata": {
        "id": "yEiBdqu64WhE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EooqvxrZ_-Tq",
        "outputId": "32dcb603-2bf1-4718-c32e-2d5d4c644e63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.1.5\n",
            "  Downloading langchain-0.1.5-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.7/806.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==1.11.1\n",
            "  Downloading openai-1.11.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymilvus==2.3.6\n",
            "  Downloading pymilvus-2.3.6-py3-none-any.whl (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==4.16.0\n",
            "  Downloading gradio-4.16.0-py3-none-any.whl (16.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_openai==0.0.5\n",
            "  Downloading langchain_openai-0.0.5-py3-none-any.whl (29 kB)\n",
            "Collecting pyarrow==14.0.0\n",
            "  Downloading pyarrow-14.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.5)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.5)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.17 (from langchain==0.1.5)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain==0.1.5)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain==0.1.5)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.5) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.11.1) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai==1.11.1)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai==1.11.1) (4.10.0)\n",
            "Requirement already satisfied: setuptools>=67 in /usr/local/lib/python3.10/dist-packages (from pymilvus==2.3.6) (67.7.2)\n",
            "Collecting grpcio<=1.60.0,>=1.49.1 (from pymilvus==2.3.6)\n",
            "  Downloading grpcio-1.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus==2.3.6) (3.20.3)\n",
            "Collecting environs<=9.5.0 (from pymilvus==2.3.6)\n",
            "  Downloading environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting ujson>=2.0.0 (from pymilvus==2.3.6)\n",
            "  Downloading ujson-5.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.2/53.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus==2.3.6) (1.5.3)\n",
            "Collecting minio>=7.0.0 (from pymilvus==2.3.6)\n",
            "  Downloading minio-7.2.5-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio==4.16.0)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (4.2.2)\n",
            "Collecting fastapi (from gradio==4.16.0)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==4.16.0)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.8.1 (from gradio==4.16.0)\n",
            "  Downloading gradio_client-0.8.1-py3-none-any.whl (305 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.2/305.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (6.3.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==4.16.0)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (24.0)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (9.4.0)\n",
            "Collecting pydub (from gradio==4.16.0)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==4.16.0)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting ruff>=0.1.7 (from gradio==4.16.0)\n",
            "  Downloading ruff-0.3.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==4.16.0)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio==4.16.0)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio==4.16.0) (0.9.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==4.16.0)\n",
            "  Downloading uvicorn-0.29.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<0.6.0,>=0.5.2 (from langchain_openai==0.0.5)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.8.1->gradio==4.16.0) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.8.1->gradio==4.16.0)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.5) (1.9.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==4.16.0) (0.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.11.1) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.11.1) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.5)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.5)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting python-dotenv (from environs<=9.5.0->pymilvus==2.3.6)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.11.1) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.11.1)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.11.1)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio==4.16.0) (3.13.1)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.5)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community<0.1,>=0.0.17 (from langchain==0.1.5)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.26-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.23-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.22-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.16 (from langchain==0.1.5)\n",
            "  Downloading langchain_core-0.1.31-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.29-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.27-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.1.24-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain==0.1.5)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging (from gradio==4.16.0)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==4.16.0) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus==2.3.6) (2.0.7)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus==2.3.6) (23.1.0)\n",
            "Collecting pycryptodome (from minio>=7.0.0->pymilvus==2.3.6)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus==2.3.6) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.5) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.5) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.5) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.5) (3.0.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<0.6.0,>=0.5.2->langchain_openai==0.0.5) (2023.12.25)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio==4.16.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio==4.16.0)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio==4.16.0) (13.7.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio==4.16.0)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.16.0) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.16.0) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0) (2.16.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.5)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio>=7.0.0->pymilvus==2.3.6) (21.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio==4.16.0) (0.1.2)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus==2.3.6) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus==2.3.6) (2.21)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=8fdee56acb065f9336d410658f6340972a7a434bfd0ffe69684dedf5d8682442\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, pycryptodome, pyarrow, packaging, orjson, mypy-extensions, jsonpointer, h11, grpcio, colorama, aiofiles, uvicorn, typing-inspect, tiktoken, starlette, marshmallow, jsonpatch, httpcore, langsmith, httpx, fastapi, environs, dataclasses-json, openai, minio, langchain-core, gradio-client, pymilvus, langchain_openai, langchain-community, gradio, langchain\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.62.1\n",
            "    Uninstalling grpcio-1.62.1:\n",
            "      Successfully uninstalled grpcio-1.62.1\n",
            "Successfully installed aiofiles-23.2.1 colorama-0.4.6 dataclasses-json-0.6.4 environs-9.5.0 fastapi-0.110.0 ffmpy-0.3.2 gradio-4.16.0 gradio-client-0.8.1 grpcio-1.60.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.5 langchain-community-0.0.20 langchain-core-0.1.23 langchain_openai-0.0.5 langsmith-0.0.87 marshmallow-3.21.1 minio-7.2.5 mypy-extensions-1.0.0 openai-1.11.1 orjson-3.9.15 packaging-23.2 pyarrow-14.0.0 pycryptodome-3.20.0 pydub-0.25.1 pymilvus-2.3.6 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.3.3 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tiktoken-0.5.2 tomlkit-0.12.0 typing-inspect-0.9.0 ujson-5.9.0 uvicorn-0.29.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.1.5 \\\n",
        "  openai==1.11.1 \\\n",
        "  pymilvus==2.3.6 \\\n",
        "  gradio==4.16.0 \\\n",
        "  langchain_openai==0.0.5 \\\n",
        "  pyarrow==14.0.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For forcing the versions"
      ],
      "metadata": {
        "id": "1KLWAdVn6Sar"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read our CSV in python.\n"
      ],
      "metadata": {
        "id": "Ieb0h7aFAI2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read CSV file into a DataFrame\n",
        "df = pd.read_csv('appendix_data.csv')"
      ],
      "metadata": {
        "id": "SGXcq42IBZrd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After you run this cell you'll need to load the data at https://zilliz.com"
      ],
      "metadata": {
        "id": "ABNGz3URlZRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import (\n",
        "    Collection,\n",
        "    CollectionSchema,\n",
        "    connections,\n",
        "    DataType,\n",
        "    FieldSchema,\n",
        "    utility,\n",
        "    MilvusClient\n",
        ")\n",
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "COLLECTION_NAME = 'content'  # Collection name\n",
        "EMBEDDING_DIMENSION = 1536  # Embedding vector size, specified by OpenAI\n",
        "ZILLIZ_CLLUSTER_URI = 'YOUR_ZILLIZ_URI'  # Endpoint URI obtained from Zilliz Cloud\n",
        "ZILLIZ_API_KEY = 'YOUR_ZILLZ_API_KEY'\n",
        "OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY'\n",
        "\n",
        "connections.connect(uri=ZILLIZ_CLLUSTER_URI, token=ZILLIZ_API_KEY, secure=True)\n",
        "\n",
        "\n",
        "##  If the data already exists, drop it so we don't end up pushing up duplicates\n",
        "if utility.has_collection(COLLECTION_NAME):\n",
        "    utility.drop_collection(COLLECTION_NAME)\n",
        "\n",
        "# Create collection which includes the id, title, and embedding.\n",
        "fields = [\n",
        "  FieldSchema(name='id', dtype=DataType.VARCHAR, is_primary=True, auto_id=True, max_length=36),\n",
        "  FieldSchema(name='author', dtype=DataType.VARCHAR, max_length=200),\n",
        "  FieldSchema(name='text', dtype=DataType.VARCHAR, max_length=2000),\n",
        "  FieldSchema(name='vector', dtype=DataType.FLOAT_VECTOR, dim=EMBEDDING_DIMENSION)\n",
        "]\n",
        "\n",
        "schema = CollectionSchema(fields=fields)\n",
        "collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
        "\n",
        "# Create an index for the collection.\n",
        "index_params = {\n",
        "    'index_type': 'AUTOINDEX',\n",
        "    'metric_type': 'IP',\n",
        "    'params': {}\n",
        "}\n",
        "\n",
        "\n",
        "collection.create_index(field_name=\"vector\", index_params=index_params)\n",
        "\n",
        "milvusClient = MilvusClient(\n",
        "    uri=ZILLIZ_CLLUSTER_URI,\n",
        "    token=ZILLIZ_API_KEY)\n",
        "\n",
        "openAIClient = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "## initialize list to store data that will be inserted into the collection.  Then we're iterating through rows of the dataframe and appends information as a dictionary.  Giving us a list of dictionaries.\n",
        "rows = []\n",
        "for row in df.to_records():\n",
        "  rows.append({\n",
        "      'author': row[1],\n",
        "      'text': row[2],\n",
        "      'vector': openAIClient.embeddings.create(\n",
        "          input=row[2],\n",
        "          model='text-embedding-ada-002').data[0].embedding\n",
        "  })\n",
        "\n",
        "## inserts the data in \"rows\" into the collection\n",
        "milvusClient.insert(COLLECTION_NAME, rows)\n"
      ],
      "metadata": {
        "id": "afRJFT8eGLgi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de438e3e-53f2-4fda-c81b-08f6e3a4ea6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:pymilvus.milvus_client.milvus_client:Created new connection using: a6acb06500d440f0a4d987d45b8bdfa7\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['448076123400628635',\n",
              " '448076123400628636',\n",
              " '448076123400628637',\n",
              " '448076123400628638',\n",
              " '448076123400628639',\n",
              " '448076123400628640',\n",
              " '448076123400628641',\n",
              " '448076123400628642',\n",
              " '448076123400628643',\n",
              " '448076123400628644',\n",
              " '448076123400628645',\n",
              " '448076123400628646',\n",
              " '448076123400628647',\n",
              " '448076123400628648',\n",
              " '448076123400628649',\n",
              " '448076123400628650',\n",
              " '448076123400628651',\n",
              " '448076123400628652',\n",
              " '448076123400628653',\n",
              " '448076123400628654',\n",
              " '448076123400628655',\n",
              " '448076123400628656',\n",
              " '448076123400628657',\n",
              " '448076123400628658',\n",
              " '448076123400628659',\n",
              " '448076123400628660',\n",
              " '448076123400628661',\n",
              " '448076123400628662',\n",
              " '448076123400628663',\n",
              " '448076123400628664']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "'itemgetter' is for extracting elements from data\n",
        "structures.\n",
        "'os' is for communicating with the operating system.\n",
        "importing FAISS is for similarity search of vectors."
      ],
      "metadata": {
        "id": "pOGDX-bg7oEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import itemgetter\n",
        "import os\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Milvus\n",
        "from langchain.globals import set_debug, set_verbose\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "from openai import OpenAI\n",
        "from typing import List\n",
        "from pymilvus import (\n",
        "    connections,\n",
        "    MilvusClient\n",
        ")\n",
        "\n",
        "set_verbose(True)\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
        "\n",
        "connections.connect(uri=ZILLIZ_CLLUSTER_URI, token=ZILLIZ_API_KEY, secure=True)\n",
        "\n",
        "milvusClient = MilvusClient(\n",
        "    uri=ZILLIZ_CLLUSTER_URI,\n",
        "    token=ZILLIZ_API_KEY)\n",
        "\n",
        "class ZillizRetriever(BaseRetriever):\n",
        "\n",
        "    def _get_relevant_documents(\n",
        "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
        "    ) -> List[Document]:\n",
        "        results = milvusClient.search(\n",
        "          collection_name=COLLECTION_NAME,\n",
        "          data = [openAIClient.embeddings.create(input=query,\n",
        "                                                model='text-embedding-ada-002').data[0].embedding],\n",
        "          limit=3,\n",
        "          output_fields=[\"author\", \"text\"])\n",
        "\n",
        "        docs = []\n",
        "        for result in results[0]:\n",
        "          doc = Document(page_content=result['entity']['text'])\n",
        "          docs.append(doc)\n",
        "        return docs\n",
        "\n",
        "\n",
        "def get_response(question, language):\n",
        "  retriever = ZillizRetriever()\n",
        "\n",
        "\n",
        "  template = \"\"\"Answer the question based only on the following context and formatted as an email:\n",
        "  {context}\n",
        "\n",
        "  Question: {question}\n",
        "\n",
        "  Answer in the following language: {language}\n",
        "  \"\"\"\n",
        "\n",
        "  prompt = ChatPromptTemplate.from_template(template)\n",
        "  model = ChatOpenAI()\n",
        "\n",
        "  chain = (\n",
        "      {\n",
        "         \"context\": itemgetter(\"question\") | retriever,\n",
        "         \"question\": itemgetter(\"question\"),\n",
        "          \"language\": itemgetter(\"language\"),\n",
        "     }\n",
        "      | prompt\n",
        "      | model\n",
        "      | StrOutputParser()\n",
        "  )\n",
        "  return chain.invoke({'question': question, 'language': language})\n",
        "\n",
        "\n",
        "\n",
        "#chain.invoke({'question': \"What is the focus for this year?\", 'language': 'english'})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JoYe3YQqvr0",
        "outputId": "8bc28633-e71a-40a9-f082-e0bcf148d301"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:pymilvus.milvus_client.milvus_client:Created new connection using: 327d7acb4bd94e7d91f3192eb790741f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "dLmimINfRdDR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=get_response,\n",
        "    inputs=[\"text\", \"text\"],\n",
        "    outputs=\"text\",\n",
        "    live=True,\n",
        "    title=\"Content App\",\n",
        "    description=\"Ask a question for killer content\",\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "rNgul6IsSsLR",
        "outputId": "2e20418c-0082-45a6-e457-e6aad8f05003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://889b7521e463da738a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://889b7521e463da738a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r64FFiXQf3dN",
        "outputId": "7fcf8f71-8ffc-444f-8108-daa67ffcd95e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:pymilvus.milvus_client.milvus_client:Created new connection using: 83634f801a314952860fc4f8a9eafdd3\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:860: UserWarning: Expected 3 arguments for function <function get_response at 0x7c1825125cf0>, received 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/utils.py:864: UserWarning: Expected at least 3 arguments for function <function get_response at 0x7c1825125cf0>, received 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://6478c652ae17afffba.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6478c652ae17afffba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from operator import itemgetter\n",
        "import os\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Milvus\n",
        "from langchain.globals import set_debug, set_verbose\n",
        "from langchain_core.retrievers import BaseRetriever\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.callbacks import CallbackManagerForRetrieverRun\n",
        "from openai import OpenAI\n",
        "from typing import List\n",
        "from pymilvus import (\n",
        "    connections,\n",
        "    MilvusClient\n",
        ")\n",
        "\n",
        "set_verbose(True)\n",
        "os.environ['OPENAI_API_KEY'] = \"YOUR_OPENAI_API_KEY\"  # Replace with your actual API key\n",
        "\n",
        "connections.connect(uri=ZILLIZ_CLLUSTER_URI, token=ZILLIZ_API_KEY, secure=True)\n",
        "\n",
        "milvusClient = MilvusClient(\n",
        "    uri=ZILLIZ_CLLUSTER_URI,\n",
        "    token=ZILLIZ_API_KEY)\n",
        "\n",
        "class ZillizRetriever(BaseRetriever):\n",
        "    def _get_relevant_documents(\n",
        "        self, query: str, *, run_manager: CallbackManagerForRetrieverRun\n",
        "    ) -> List[Document]:\n",
        "        results = milvusClient.search(\n",
        "            collection_name=\"YOUR_COLLECTION_NAME\",  # Replace with your actual collection name\n",
        "            data=[openAIClient.embeddings.create(input=query, model='text-embedding-ada-002').data[0].embedding],\n",
        "            limit=3,\n",
        "            output_fields=[\"author\", \"text\"])\n",
        "\n",
        "        docs = []\n",
        "        for result in results[0]:\n",
        "            doc = Document(page_content=result['entity']['text'])\n",
        "            docs.append(doc)\n",
        "        return docs\n",
        "\n",
        "def get_response(question):\n",
        "    retriever = ZillizRetriever()\n",
        "\n",
        "    # Define response templates\n",
        "    template1 = \"\"\"Template 1: Answer the question based only on the following context and formatted as an email:\n",
        "    {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    template2 = \"\"\"Template 2: Answer the question using a different format:\n",
        "    {context}\n",
        "\n",
        "    Question: {question}\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    prompt1 = ChatPromptTemplate.from_template(template1)\n",
        "    prompt2 = ChatPromptTemplate.from_template(template2)\n",
        "    model = ChatOpenAI()\n",
        "\n",
        "    chain1 = (\n",
        "        {\n",
        "            \"context\": itemgetter(\"question\") | retriever,\n",
        "            \"question\": itemgetter(\"question\"),\n",
        "        }\n",
        "        | prompt1\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    chain2 = (\n",
        "        {\n",
        "            \"context\": itemgetter(\"question\") | retriever,\n",
        "            \"question\": itemgetter(\"question\"),\n",
        "        }\n",
        "        | prompt2\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "\n",
        "    return f\"{chain1.invoke({'question': question})}\\n\\n{chain2.invoke({'question': question})}\"\n",
        "\n",
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=get_response,\n",
        "    inputs=gr.Textbox(\"text\", label=\"Enter your question\"),\n",
        "    outputs=[\"text\", \"text\"],\n",
        "    live=True,\n",
        "    title=\"Engagys Content App\",\n",
        "    description=\"Ask a question and get two different answers based on different templates.\"\n",
        ")\n",
        "\n",
        "iface.launch()"
      ],
      "metadata": {
        "id": "fCl99cVOcVzA",
        "outputId": "1ab8de30-40cf-458d-aa14-3ae2e7490584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:pymilvus.milvus_client.milvus_client:Created new connection using: 78ea8dc5c05b4ef99247bec0ca51aea3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://1072baa0c96bf7e6ad.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1072baa0c96bf7e6ad.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    }
  ]
}