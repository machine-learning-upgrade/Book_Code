{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# this thing....\n",
        "!pip3 install --no-cache-dir  --force-reinstall -Iv grpcio==1.49.1"
      ],
      "metadata": {
        "id": "_0pWRrSxyHi3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "dd99ffb0-fb02-4f32-ba36-c6f79520d15a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Collecting grpcio==1.49.1\n",
            "  Downloading grpcio-1.49.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting six>=1.5.2 (from grpcio==1.49.1)\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: six, grpcio\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-1.49.1 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewI3se7iuXt3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72506638-70a6-4d85-f791-48662ee3d497"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymilvus\n",
            "  Downloading pymilvus-2.3.3-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain\n",
            "  Downloading langchain-0.0.335-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.2.4-py3-none-any.whl (220 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.2/220.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<=1.58.0,>=1.49.1 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.49.1)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (3.20.3)\n",
            "Collecting environs<=9.5.0 (from pymilvus)\n",
            "  Downloading environs-9.5.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting ujson>=2.0.0 (from pymilvus)\n",
            "  Downloading ujson-5.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.10/dist-packages (from pymilvus) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pymilvus) (2.31.0)\n",
            "Collecting minio>=7.0.0 (from pymilvus)\n",
            "  Downloading minio-7.2.0-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.64-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.25.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting python-dotenv (from environs<=9.5.0->pymilvus)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from grpcio<=1.58.0,>=1.49.1->pymilvus) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Collecting httpcore (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus) (2.0.7)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio>=7.0.0->pymilvus) (23.1.0)\n",
            "Collecting pycryptodome (from minio>=7.0.0->pymilvus)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.4->pymilvus) (2023.3.post1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio>=7.0.0->pymilvus) (21.2.0)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio>=7.0.0->pymilvus) (2.21)\n",
            "Installing collected packages: ujson, pytube, python-dotenv, pycryptodome, mypy-extensions, marshmallow, jsonpointer, h11, youtube_transcript_api, typing-inspect, langsmith, jsonpatch, httpcore, environs, httpx, dataclasses-json, openai, minio, langchain, pymilvus\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.2 environs-9.5.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.335 langsmith-0.0.64 marshmallow-3.20.1 minio-7.2.0 mypy-extensions-1.0.0 openai-1.2.4 pycryptodome-3.19.0 pymilvus-2.3.3 python-dotenv-1.0.0 pytube-15.0.0 typing-inspect-0.9.0 ujson-5.8.0 youtube_transcript_api-0.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install \\\n",
        "pymilvus \\\n",
        "langchain \\\n",
        "openai \\\n",
        "youtube_transcript_api \\\n",
        "pytube"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymilvus import (MilvusClient\n",
        "                      , connections\n",
        "                      , Collection\n",
        "                      , CollectionSchema\n",
        "                      , FieldSchema\n",
        "                      , DataType\n",
        "                      , utility)\n",
        "import json\n",
        "\n",
        "\n",
        "COLLECTION_NAME = 'youtube'\n",
        "EMBEDDING_DIMENSION = 1536  # Embedding vector size in this example\n",
        "ZILLIZ_CLUSTER_URI = 'https://in03-8e8b6b5971b3223.api.gcp-us-west1.zillizcloud.com'  # Endpoint URI obtained from Zilliz Cloud\n",
        "ZILLIZ_API_KEY = '46dcc1502bfcc6ea9f5869ef9481a0dd200bf426f92a7e26c77a96602c79bc1fe27cf5ff6cdae7acc29feba362ebc899fcb96cd9'\n",
        "\n",
        "YT_VIDEO_URLS = [\n",
        "    \"https://www.youtube.com/watch?v=Q4OBx3S0Ysw&t=118s\",\n",
        "    \"https://youtu.be/4OZip0cgOho?si=KHUsA4J8L3rbZAAZ\"]\n",
        "\n",
        "# Connect to the zilliz cluster\n",
        "connections.connect(uri=ZILLIZ_CLUSTER_URI, token=ZILLIZ_API_KEY, secure=True)\n",
        "\n",
        "# Remove any previous collections with the same name\n",
        "if utility.has_collection(COLLECTION_NAME):\n",
        "    utility.drop_collection(COLLECTION_NAME)\n",
        "\n",
        "# Create collection which includes the id, title, and embedding.\n",
        "fields = [\n",
        "  FieldSchema(name='id', dtype=DataType.VARCHAR, is_primary=True, auto_id=False, max_length=36),\n",
        "  FieldSchema(name='video_id', dtype=DataType.INT64,),\n",
        "  FieldSchema(name='title', dtype=DataType.VARCHAR, description='Title texts', max_length=500),\n",
        "  FieldSchema(name='author', dtype=DataType.VARCHAR, description='Author', max_length=200),\n",
        "  FieldSchema(name='part_id', dtype=DataType.INT64),\n",
        "  FieldSchema(name='max_part_id', dtype=DataType.INT64),\n",
        "  FieldSchema(name='text', dtype=DataType.VARCHAR, description='Text of chunk', max_length=2000),\n",
        "  FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, description='Embedding vectors', dim=EMBEDDING_DIMENSION)\n",
        "]\n",
        "\n",
        "schema = CollectionSchema(fields=fields)\n",
        "\n",
        "collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
        "\n",
        "# Create an index for the collection.\n",
        "index_params = {\n",
        "    'index_type': 'AUTOINDEX',\n",
        "    'metric_type': 'IP',\n",
        "    'params': {}\n",
        "}\n",
        "\n",
        "\n",
        "collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SxtZXNoewwpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b8e1fe-0330-400a-f142-273d1c52ef5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Status(code=0, message=)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from openai import OpenAI\n",
        "from pymilvus import MilvusClient, connections\n",
        "from uuid import uuid4\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "import youtube_transcript_api\n",
        "import pytube\n",
        "\n",
        "connections.connect(uri=ZILLIZ_CLUSTER_URI, token=ZILLIZ_API_KEY, secure=True)\n",
        "\n",
        "client = MilvusClient(\n",
        "    uri=ZILLIZ_CLUSTER_URI,\n",
        "    token=ZILLIZ_API_KEY)\n",
        "\n",
        "\n",
        "\n",
        "openai_client = OpenAI(\n",
        "    # defaults to os.environ.get(\"OPENAI_API_KEY\")\n",
        "    api_key=\"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\",\n",
        ")\n",
        "\n",
        "# Extract embedding from text using OpenAI  string -> vector\n",
        "# This function is directly from https://docs.zilliz.com/docs/similarity-search-with-zilliz-cloud-and-openai, but with \"text-embedding-ada-002\" added.\n",
        "def create_embedding_from_string(text):\n",
        "    return openai_client.embeddings.create(\n",
        "        input=text,\n",
        "        model='text-embedding-ada-002').data[0].embedding\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "  chunk_size = 1000,\n",
        "  chunk_overlap  = 50,\n",
        "  length_function = len,\n",
        "  add_start_index = True,\n",
        ")\n",
        "\n",
        "for video_id, url in enumerate(YT_VIDEO_URLS):\n",
        "\n",
        "  yt_data = YoutubeLoader.from_youtube_url(url, add_video_info=True).load()[0]\n",
        "  video_parts = text_splitter.create_documents([yt_data.page_content])\n",
        "\n",
        "  for part_id, part in enumerate(video_parts):\n",
        "      client.insert(\n",
        "        collection_name=COLLECTION_NAME,\n",
        "        data={\n",
        "            'id': str(uuid4()),\n",
        "            'video_id': video_id,\n",
        "            'title': yt_data.metadata['title'],\n",
        "            'author': yt_data.metadata['author'],\n",
        "            'part_id': part_id,\n",
        "            'max_part_id': len(video_parts),\n",
        "            'text': part.page_content,\n",
        "            'embedding': create_embedding_from_string(part.page_content)\n",
        "        })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVOv0eDFXjLM",
        "outputId": "aa214461-6b99-4ebc-bb15-16db471a9d07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:pymilvus.milvus_client.milvus_client:Created new connection using: 21c920b67f1a414c85199c254631c723\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = collection.query(\n",
        "    expr='title != \"none\"',\n",
        "    output_fields=['title', 'author', 'part_id', 'max_part_id', 'text'])\n",
        "\n",
        "with open('data.json', 'w') as file:\n",
        "  file.write(json.dumps(results, indent=2))"
      ],
      "metadata": {
        "id": "aeBj9xabXfyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install comet_ml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkHb042klta0",
        "outputId": "56d2bc32-42ee-48bb-caf1-3c2f77b06683"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting comet_ml\n",
            "  Downloading comet_ml-3.35.3-py3-none-any.whl (586 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/586.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/586.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m583.7/586.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.4/586.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (4.19.2)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (5.9.5)\n",
            "Collecting python-box<7.0.0 (from comet_ml)\n",
            "  Downloading python_box-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt>=0.8.0 (from comet_ml)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.31.0)\n",
            "Collecting semantic-version>=2.8.0 (from comet_ml)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting sentry-sdk>=1.1.0 (from comet_ml)\n",
            "  Downloading sentry_sdk-1.35.0-py2.py3-none-any.whl (248 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson (from comet_ml)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (2.0.7)\n",
            "Collecting websocket-client<1.4.0,>=0.55.0 (from comet_ml)\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (1.14.1)\n",
            "Collecting wurlitzer>=1.0.2 (from comet_ml)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Collecting everett[ini]<3.2.0,>=1.0.1 (from comet_ml)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n",
            "  Downloading dulwich-0.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (512 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.2/512.2 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.10/dist-packages (from comet_ml) (13.6.0)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.18.4->comet_ml) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.3.2->comet_ml) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Installing collected packages: everett, wurlitzer, websocket-client, simplejson, sentry-sdk, semantic-version, python-box, dulwich, configobj, requests-toolbelt, comet_ml\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.6.4\n",
            "    Uninstalling websocket-client-1.6.4:\n",
            "      Successfully uninstalled websocket-client-1.6.4\n",
            "  Attempting uninstall: python-box\n",
            "    Found existing installation: python-box 7.1.1\n",
            "    Uninstalling python-box-7.1.1:\n",
            "      Successfully uninstalled python-box-7.1.1\n",
            "Successfully installed comet_ml-3.35.3 configobj-5.0.8 dulwich-0.21.6 everett-3.1.0 python-box-6.1.0 requests-toolbelt-1.0.0 semantic-version-2.10.0 sentry-sdk-1.35.0 simplejson-3.19.2 websocket-client-1.3.3 wurlitzer-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## import comet_ml at the top of your file\n",
        "from comet_ml import Experiment, Artifact\n",
        "\n",
        "## Create an experiment with your api key\n",
        "experiment = Experiment(\n",
        "    api_key=\"W7YKQ5vMSQ2zreCkA9uf3wUy7\",\n",
        "    project_name=\"youtube-transcriptions\",\n",
        "    workspace=\"machine-learning-upgrade\",\n",
        ")\n",
        "\n",
        "artifact = Artifact(name=\"milvus-query-results\", artifact_type=\"dataset\")\n",
        "artifact.add(\"data.json\")\n",
        "\n",
        "experiment.log_artifact(artifact)\n",
        "experiment.end()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq34gBPbucza",
        "outputId": "ced53cc9-a1e8-48ea-fd9d-3d6986e574da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: openai.\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/machine-learning-upgrade/youtube-transcriptions/84885cfb2d7540f49b7997d46040c410\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'milvus-query-results' version 5.0.0 created (previous was: 4.0.0)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Scheduling the upload of 1 assets for a size of 21.01 KB, this can take some time\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'machine-learning-upgrade/milvus-query-results:5.0.0' has started uploading asynchronously\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/machine-learning-upgrade/youtube-transcriptions/84885cfb2d7540f49b7997d46040c410\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifact assets     : 1 (21.01 KB)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     artifacts           : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: openai.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Artifact 'machine-learning-upgrade/milvus-query-results:5.0.0' has been fully uploaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "\n",
        "loader = YoutubeLoader.from_youtube_url(\n",
        "    \"https://www.youtube.com/watch?v=Q4OBx3S0Ysw&t=118s\", add_video_info=True\n",
        ")\n",
        "\n",
        "data = loader.load()\n",
        "data[0].page_content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "6QK8fahg58gp",
        "outputId": "72b15da0-875d-4599-9a23-127f03dd3d36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"foreign [Applause] to perform Vector similarity search on images zillas is a vector database it is designed to handle massive data sets containing vectors vectors are just numerical representations of data so this is your text documents audio and that also includes images traditional methods of searching through these large data sets has been consuming and computationally expensive so zilis uses Advanced algorithms and data structures tailored specifically for Vector similarity search instead of comparing each point individually zilla's organizes these vectors in a way that optimizes similarity queries this allows you to quickly find items that are similar to a given query vector so is this focused on cutting-edge Technologies for data indexing storage and retrieval with an emphasis on GPU accelerated computing for a high level overview of this project we are going to get the connection from The Notebook to Melvis and set up a cluster we're going to import images from Google Drive I'll make sure to leave a link in the description we're going to set up zilla's Cloud we're going to insert our data and then we will do our similarity search using a resnet 50 model and then we're going to go back again and do it with resnet 152 to just compare the output and see how it's different to get started the first thing that you'll want to do is set yourself up azilla's account when you do that you will have a hundred dollars worth of free credits so that you'll be able to follow along with this demo for free I'm going to create a cluster and then we'll go over downloading the images creating the embeddings modeling those but then we'll be able to write those embeddings over to the milvis database I will be using the starter serverless plan and I'm just going to give this the name image search so that's the name of my collection the metric type there are two options and I'm going to be choosing this L2 which is just your standard euclidean distance all right so now I am going to put the public endpoint in my code I already have the API key over there copy this and you'll see that image search has been set up but that it doesn't actually have any data for us I'm going to add my URI [Music] like I said my API key is already here all right so now we're going to dive into this demo here is a Google Drive link that you can use to access the images that I'm using they are images of my family but if you want to go along with your own images that'll work too so we're starting like we normally do by pip installing our packages we'll restart our run time and then now I am just going to be setting up my directory to match the docs and so we are in the content folder and then I'll add one for python as well oh okay so now this should work all right so we are going to pip install a couple more libraries Pine milfus is going to be used to connect to zilla's Cloud we're going to use torch to run the embedding model we will use torch vision for the actual model and pre-processing and then G down is for working with Google Drive and the tqdm package is so that we get those cute little loading bars while our model is training then we will import these libraries here are the docs for starting here these docs are what I followed to put this together and so here you're going to need to add the Google Drive Link so you could use the link above open that up actually let me make sure that that works then we are going to set the output path and file name for the downloaded file and then download the file from the given Google Drive Link using gdam all right perfect so that link I gave you works next we're just going to be setting our parameters so we had given the collection name image search you had already seen me put my URI and I had already put my API key here and then now we need to set up our cloud so we will be first connecting to the zillas cloud cluster using the URI that we had there it's just if the collection already exists drop it okay and now we're going to be setting up our schema so it's going to have the ID the file path and the image embedding and we will now create an index on that collection here is that L2 euclidean distance metric that we already talked about and this is just to get the file path of the different images we have 1619 images okay so here we are going to create our base model using resnet 50. and this is actually not creating the model it is defining the model if you haven't used torch before I learned this the first time that I use torch is that they actually build their neural net models sequentially by adding the different layers so that's where we get this sequential function here we're creating a preprocessor for making sure the images are the same size so we're going to resize crop normalize or at least we're setting up a preprocessor so we didn't actually do those steps here but we created a function that will allow us to do that now we're going to insert the data so this one takes a minute to run but we're going to embed the function that embeds the batch and inserts it then we're going to read the images into batches for embedding and insertion and here we're actually going to insert the data all right I hope you're ready because we are about to perform our search now for this I have already placed four images that all looked different that we can do our search on the code here is going to go through and embed the images so this is the process of converting these photos into vectors using our resnet 50 model and we are going to iterate through and use that preprocessor that we set up that'll crop and normalize the images um then we're going to do the search through these embeddings for similar images and then at the end um it'll be using matplotlib to set up a visual display for us that will list the search time and the distance of the chosen searched photo to the image that I provided okay so let's get started all right perfect so we have our output and I am just going to store this so that we are able to do a comparison in a little bit once we have the output from our next model okay and now I'm just going to go through and actually update this to be using resnet 152 and rerun [Music] awesome now we get to go take a look at these results I actually went back and ran this a couple more times myself and found that in general the resnet 152 model had shorter search times or shorter distances but that was not always the case at all and even in our results we're going to see a lot of instances where the resnet 50 has shorter distances here though we will see that the resnet 152 model the search time was about three times faster than resnet 152. taking a look at the first photo we see that all the distances for the resnet 152 model are shorter compared to the resnet 50 model and really the only photo that looks different here is the last result in the second row of results the distances are actually larger with the resnet 152 model and you can really see this because the second result returned from the 152 results my daughter has her arms in and we'd assume that the ones that have the arms out are going to be more similar to the given photo in the third row of results it's my daughter and husband with their arms up wearing coats and the distances again they're higher with the resnet 152 model even though these are super close results and you get to benefit from the faster search time in the fourth row of results all the images look really similar with the exception of where is my son placed because you can't really see him in the given photo and then in the search results he's sort of in different places the distance for the first result is very close but then the distance for the resnet 152 model is much larger for the other two photos but again the search was quicker I hope you enjoyed this demo where we did Vector similarity search using images be sure to like And subscribe and I look forward to seeing you in my next demo\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdN4AryxDH2I",
        "outputId": "b55ca781-1424-46f3-976c-486c41d1342c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "aiohttp==3.8.6\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.13\n",
            "albumentations==1.3.1\n",
            "altair==4.2.2\n",
            "anyio==3.7.1\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array-record==0.5.0\n",
            "arviz==0.15.1\n",
            "astropy==5.3.4\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.0\n",
            "attrs==23.1.0\n",
            "audioread==3.0.1\n",
            "autograd==1.6.2\n",
            "Babel==2.13.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.11.2\n",
            "bidict==0.22.1\n",
            "bigframes==0.13.0\n",
            "bleach==6.1.0\n",
            "blinker==1.4\n",
            "blis==0.7.11\n",
            "blosc2==2.0.0\n",
            "bokeh==3.3.0\n",
            "bqplot==0.12.42\n",
            "branca==0.7.0\n",
            "build==1.0.3\n",
            "CacheControl==0.13.1\n",
            "cachetools==5.3.2\n",
            "catalogue==2.0.10\n",
            "certifi==2023.7.22\n",
            "cffi==1.16.0\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.3.2\n",
            "chex==0.1.7\n",
            "click==8.1.7\n",
            "click-plugins==1.1.1\n",
            "cligj==0.7.2\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.27.7\n",
            "cmdstanpy==1.2.0\n",
            "colorcet==3.0.1\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.3\n",
            "cons==0.4.6\n",
            "contextlib2==21.6.0\n",
            "contourpy==1.2.0\n",
            "cryptography==41.0.5\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda11x==11.0.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.3.2\n",
            "cycler==0.12.1\n",
            "cymem==2.0.8\n",
            "Cython==3.0.5\n",
            "dask==2023.8.1\n",
            "dataclasses-json==0.6.2\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.1.1\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "diskcache==5.6.3\n",
            "distributed==2023.8.1\n",
            "distro==1.7.0\n",
            "dlib==19.24.2\n",
            "dm-tree==0.1.8\n",
            "docutils==0.18.1\n",
            "dopamine-rl==4.0.6\n",
            "duckdb==0.9.1\n",
            "earthengine-api==0.1.377\n",
            "easydict==1.11\n",
            "ecos==2.0.12\n",
            "editdistance==0.6.2\n",
            "eerepr==0.0.4\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl#sha256=83276fc78a70045627144786b52e1f2728ad5e29e5e43916ec37ea9c26a11212\n",
            "entrypoints==0.4\n",
            "environs==9.5.0\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.5.2\n",
            "etuples==0.3.9\n",
            "exceptiongroup==1.1.3\n",
            "fastai==2.7.13\n",
            "fastcore==1.5.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.18.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.13.1\n",
            "fiona==1.9.5\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.5\n",
            "flatbuffers==23.5.26\n",
            "flax==0.7.5\n",
            "folium==0.14.0\n",
            "fonttools==4.44.0\n",
            "frozendict==2.3.8\n",
            "frozenlist==1.4.0\n",
            "fsspec==2023.6.0\n",
            "future==0.18.3\n",
            "gast==0.5.4\n",
            "gcsfs==2023.6.0\n",
            "GDAL==3.4.3\n",
            "gdown==4.6.6\n",
            "geemap==0.28.2\n",
            "gensim==4.3.2\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==0.13.2\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==2.11.1\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.17.3\n",
            "google-auth-httplib2==0.1.1\n",
            "google-auth-oauthlib==1.0.0\n",
            "google-cloud-bigquery==3.12.0\n",
            "google-cloud-bigquery-connection==1.12.1\n",
            "google-cloud-bigquery-storage==2.22.0\n",
            "google-cloud-core==2.3.3\n",
            "google-cloud-datastore==2.15.2\n",
            "google-cloud-firestore==2.11.1\n",
            "google-cloud-functions==1.13.3\n",
            "google-cloud-iam==2.12.2\n",
            "google-cloud-language==2.9.1\n",
            "google-cloud-resource-manager==1.10.4\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.3\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=30643dfaefcf2f02b95cf390d5db41eca40b081b8fd3a60253db67c02912d669\n",
            "google-crc32c==1.5.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.6.0\n",
            "googleapis-common-protos==1.61.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.1\n",
            "greenlet==3.0.1\n",
            "grpc-google-iam-v1==0.12.6\n",
            "grpcio==1.49.1\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h11==0.14.0\n",
            "h5netcdf==1.3.0\n",
            "h5py==3.9.0\n",
            "holidays==0.36\n",
            "holoviews==1.17.1\n",
            "html5lib==1.1\n",
            "httpcore==1.0.2\n",
            "httpimport==1.3.1\n",
            "httplib2==0.22.0\n",
            "httpx==0.25.1\n",
            "humanize==4.7.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==6.2.0\n",
            "idna==3.4\n",
            "imageio==2.31.6\n",
            "imageio-ffmpeg==0.4.9\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "importlib-metadata==6.8.0\n",
            "importlib-resources==6.1.1\n",
            "imutils==0.5.4\n",
            "inflect==7.0.0\n",
            "iniconfig==2.0.0\n",
            "install==1.3.5\n",
            "intel-openmp==2023.2.0\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.17.4\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.1.2\n",
            "jax==0.4.20\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.20+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=01be66238133f884bf5adf15cd7eaaf8445f9d4b056c5c64df28a997a6aff2fe\n",
            "jeepney==0.7.1\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.2\n",
            "joblib==1.3.2\n",
            "jsonpatch==1.33\n",
            "jsonpickle==3.0.2\n",
            "jsonpointer==2.4\n",
            "jsonschema==4.19.2\n",
            "jsonschema-specifications==2023.7.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.5.0\n",
            "jupyterlab-pygments==0.2.2\n",
            "jupyterlab-widgets==3.0.9\n",
            "kaggle==1.5.16\n",
            "keras==2.14.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.5\n",
            "langchain==0.0.335\n",
            "langcodes==3.3.0\n",
            "langsmith==0.0.64\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.3\n",
            "libclang==16.0.6\n",
            "librosa==0.10.1\n",
            "lida==0.0.10\n",
            "lightgbm==4.1.0\n",
            "linkify-it-py==2.0.2\n",
            "llmx==0.0.15a0\n",
            "llvmlite==0.41.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==4.9.3\n",
            "malloy==2023.1064\n",
            "Markdown==3.5.1\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.3\n",
            "marshmallow==3.20.1\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.6\n",
            "matplotlib-venn==0.11.9\n",
            "mdit-py-plugins==0.4.0\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "minio==7.2.0\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.9.3\n",
            "mkl==2023.2.0\n",
            "ml-dtypes==0.2.0\n",
            "mlxtend==0.22.0\n",
            "more-itertools==10.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.7\n",
            "multidict==6.0.4\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.10\n",
            "music21==9.1.0\n",
            "mypy-extensions==1.0.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.0.0\n",
            "nbclient==0.9.0\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.9.2\n",
            "nest-asyncio==1.5.8\n",
            "networkx==3.2.1\n",
            "nibabel==4.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.3\n",
            "numba==0.58.1\n",
            "numexpr==2.8.7\n",
            "numpy==1.23.5\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==1.2.4\n",
            "opencv-contrib-python==4.8.0.76\n",
            "opencv-python==4.8.0.76\n",
            "opencv-python-headless==4.8.1.78\n",
            "openpyxl==3.1.2\n",
            "opt-einsum==3.3.0\n",
            "optax==0.1.7\n",
            "orbax-checkpoint==0.4.2\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.2\n",
            "pandas==1.5.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.17.9\n",
            "pandas-stubs==1.5.3.230304\n",
            "pandocfilters==1.5.0\n",
            "panel==1.3.1\n",
            "param==2.0.0\n",
            "parso==0.8.3\n",
            "parsy==2.1\n",
            "partd==1.4.1\n",
            "pathlib==1.0.1\n",
            "pathy==0.10.3\n",
            "patsy==0.5.3\n",
            "peewee==3.17.0\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==9.4.0\n",
            "pip-tools==6.13.0\n",
            "platformdirs==3.11.0\n",
            "plotly==5.15.0\n",
            "plotnine==0.12.4\n",
            "pluggy==1.3.0\n",
            "polars==0.17.3\n",
            "pooch==1.8.0\n",
            "portpicker==1.5.2\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.9\n",
            "prettytable==3.9.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus-client==0.18.0\n",
            "promise==2.3\n",
            "prompt-toolkit==3.0.39\n",
            "prophet==1.1.5\n",
            "proto-plus==1.22.3\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==9.0.0\n",
            "pyasn1==0.5.0\n",
            "pyasn1-modules==0.3.0\n",
            "pycocotools==2.0.7\n",
            "pycparser==2.21\n",
            "pycryptodome==3.19.0\n",
            "pyct==0.5.0\n",
            "pydantic==1.10.13\n",
            "pydata-google-auth==1.8.2\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.6.3\n",
            "pyerfa==2.0.1.1\n",
            "pygame==2.5.2\n",
            "Pygments==2.16.1\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.3.0\n",
            "pymc==5.7.2\n",
            "pymilvus==2.3.3\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==23.3.0\n",
            "pyparsing==3.1.1\n",
            "pyperclip==1.8.2\n",
            "pyproj==3.6.1\n",
            "pyproject_hooks==1.0.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pytensor==2.14.2\n",
            "pytest==7.4.3\n",
            "python-apt==0.0.0\n",
            "python-box==7.1.1\n",
            "python-dateutil==2.8.2\n",
            "python-dotenv==1.0.0\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.1\n",
            "python-utils==3.8.1\n",
            "pytube==15.0.0\n",
            "pytz==2023.3.post1\n",
            "pyviz_comms==3.0.0\n",
            "PyWavelets==1.4.1\n",
            "PyYAML==6.0.1\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.7.post0\n",
            "qudida==0.0.4\n",
            "ratelim==0.1.6\n",
            "referencing==0.30.2\n",
            "regex==2023.6.3\n",
            "requests==2.31.0\n",
            "requests-oauthlib==1.3.1\n",
            "requirements-parser==0.5.0\n",
            "rich==13.6.0\n",
            "rpds-py==0.12.0\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scipy==1.11.3\n",
            "scooby==0.9.2\n",
            "scs==3.2.4\n",
            "seaborn==0.12.2\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.2\n",
            "shapely==2.0.2\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.4.0\n",
            "sniffio==1.3.0\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.5\n",
            "soxr==0.3.7\n",
            "spacy==3.6.1\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==5.0.2\n",
            "sphinxcontrib-applehelp==1.0.7\n",
            "sphinxcontrib-devhelp==1.0.5\n",
            "sphinxcontrib-htmlhelp==2.0.4\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.6\n",
            "sphinxcontrib-serializinghtml==1.1.9\n",
            "SQLAlchemy==2.0.23\n",
            "sqlglot==17.16.2\n",
            "sqlparse==0.4.4\n",
            "srsly==2.4.8\n",
            "stanio==0.3.0\n",
            "statsmodels==0.14.0\n",
            "sympy==1.12\n",
            "tables==3.8.0\n",
            "tabulate==0.9.0\n",
            "tbb==2021.10.0\n",
            "tblib==3.0.0\n",
            "tenacity==8.2.3\n",
            "tensorboard==2.14.1\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow==2.14.0\n",
            "tensorflow-datasets==4.9.3\n",
            "tensorflow-estimator==2.14.0\n",
            "tensorflow-gcs-config==2.14.0\n",
            "tensorflow-hub==0.15.0\n",
            "tensorflow-io-gcs-filesystem==0.34.0\n",
            "tensorflow-metadata==1.14.0\n",
            "tensorflow-probability==0.22.0\n",
            "tensorstore==0.1.45\n",
            "termcolor==2.3.0\n",
            "terminado==0.17.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "thinc==8.1.12\n",
            "threadpoolctl==3.2.0\n",
            "tifffile==2023.9.26\n",
            "tinycss2==1.2.1\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.0\n",
            "torch @ https://download.pytorch.org/whl/cu118/torch-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=a81b554184492005543ddc32e96469f9369d778dedd195d73bda9bed407d6589\n",
            "torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.1.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=cdfd0a129406155eee595f408cafbb92589652da4090d1d2040f5453d4cae71f\n",
            "torchdata==0.7.0\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.16.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.16.0%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=033712f65d45afe806676c4129dfe601ad1321d9e092df62b15847c02d4061dc\n",
            "tornado==6.3.2\n",
            "tqdm==4.66.1\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "triton==2.1.0\n",
            "tweepy==4.14.0\n",
            "typer==0.9.0\n",
            "types-pytz==2023.3.1.1\n",
            "types-setuptools==68.2.0.1\n",
            "typing-inspect==0.9.0\n",
            "typing_extensions==4.5.0\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.2\n",
            "ujson==5.8.0\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.0.7\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wasabi==1.1.2\n",
            "wcwidth==0.2.9\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.6.4\n",
            "Werkzeug==3.0.1\n",
            "widgetsnbextension==3.6.6\n",
            "wordcloud==1.9.2\n",
            "wrapt==1.14.1\n",
            "xarray==2023.7.0\n",
            "xarray-einstats==0.6.0\n",
            "xgboost==2.0.1\n",
            "xlrd==2.0.1\n",
            "xxhash==3.4.1\n",
            "xyzservices==2023.10.1\n",
            "yarl==1.9.2\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.31\n",
            "youtube-transcript-api==0.6.1\n",
            "zict==3.0.0\n",
            "zipp==3.17.0\n"
          ]
        }
      ]
    }
  ]
}